{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluating_Sign_Detection_3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+lo9px72fQkGS24XdQt/5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nnugy-21/TensorFlow_Sign_Language_Detection/blob/main/Evaluating_Sign_Detection_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5Jxjo1NW3PH",
        "outputId": "8cc24311-baac-4655-f592-1c6ae1e0b9ce"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYazO4FgXma2",
        "outputId": "41e3d74a-5012-4719-837c-867960677108"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 2650, done.\u001b[K\n",
            "remote: Counting objects: 100% (2650/2650), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2202/2202), done.\u001b[K\n",
            "remote: Total 2650 (delta 671), reused 1297 (delta 416), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2650/2650), 32.62 MiB | 28.75 MiB/s, done.\n",
            "Resolving deltas: 100% (671/671), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMztfplMYPfN"
      },
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_QbvAsMYSz9"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import io\n",
        "import imageio\n",
        "import glob\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import colab_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNhJ_1_cYpiV"
      },
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: a file path.\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "def plot_detections(image_np,\n",
        "                    boxes,\n",
        "                    classes,\n",
        "                    scores,\n",
        "                    category_index,\n",
        "                    figsize=(10, 10),\n",
        "                    image_name=None):\n",
        "  \"\"\"Wrapper function to visualize detections.\n",
        "\n",
        "  Args:\n",
        "    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    boxes: a numpy array of shape [N, 4]\n",
        "    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n",
        "      and match the keys in the label map.\n",
        "    scores: a numpy array of shape [N] or None.  If scores=None, then\n",
        "      this function assumes that the boxes to be plotted are groundtruth\n",
        "      boxes and plot all boxes as black with no classes or scores.\n",
        "    category_index: a dict containing category dictionaries (each holding\n",
        "      category index `id` and category name `name`) keyed by category indices.\n",
        "    figsize: size for the figure.\n",
        "    image_name: a name for the image file.\n",
        "  \"\"\"\n",
        "  image_np_with_annotations = image_np.copy()\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_annotations,\n",
        "      boxes,\n",
        "      classes,\n",
        "      scores,\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      min_score_thresh=0.8)\n",
        "  if image_name:\n",
        "    plt.imsave(image_name, image_np_with_annotations)\n",
        "  else:\n",
        "    plt.imshow(image_np_with_annotations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82oOVLYJYs2v",
        "outputId": "d2a82480-0d69-4bb0-baef-e691f60e4446"
      },
      "source": [
        "#Download workspace\n",
        "#If you have your own workspace you can clone yours instead\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"TensorFlow_Sign_Language_Detection\" in pathlib.Path.cwd().parts:\n",
        "  while \"TensorFlow_Sign_Language_Detection\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('TensorFlow_Sign_Language_Detection').exists():\n",
        "  !git clone --depth 1 https://github.com/nnugy-21/TensorFlow_Sign_Language_Detection"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TensorFlow_Sign_Language_Detection'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 13 (delta 1), reused 11 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (13/13), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slEdw8oyYu5A"
      },
      "source": [
        "workspace = '/content/TensorFlow_Sign_Language_Detection/workspace'\n",
        "annotations = workspace + '/annotations'\n",
        "images = workspace + '/images'\n",
        "models = workspace + '/models'\n",
        "pre_trained_models = workspace + '/pre_trained_models'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVFuOx91YwvN",
        "outputId": "794d8047-1083-49c3-a950-4cf88c027e85"
      },
      "source": [
        "#Extracting ASL data in annotations folder\n",
        "%cd /content/TensorFlow_Sign_Language_Detection/workspace/annotations\n",
        "\n",
        "!unzip roboflow.zip\n",
        "!rm roboflow.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TensorFlow_Sign_Language_Detection/workspace/annotations\n",
            "Archive:  roboflow.zip\n",
            " extracting: test/Letters.tfrecord   \n",
            " extracting: train/Letters.tfrecord  \n",
            " extracting: valid/Letters.tfrecord  \n",
            " extracting: test/Letters_label_map.pbtxt  \n",
            " extracting: train/Letters_label_map.pbtxt  \n",
            " extracting: valid/Letters_label_map.pbtxt  \n",
            " extracting: README.roboflow.txt     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBWYIly2Yx-9"
      },
      "source": [
        "# NOTE: Update these TFRecord names and label_map_pbtxt to your file path!\n",
        "test_record_fname = annotations + '/valid/Letters.tfrecord'\n",
        "train_record_fname = annotations + '/train/Letters.tfrecord'\n",
        "label_map_pbtxt_fname = annotations + '/train/Letters_label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRZwrJkzYzYq"
      },
      "source": [
        "##change chosen model to deploy different models available in the TF2 object detection zoo\n",
        "MODELS_CONFIG = {\n",
        "    'efficientdet-d0': {\n",
        "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 16\n",
        "    },\n",
        "    'efficientdet-d1': {\n",
        "        'model_name': 'efficientdet_d1_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 16\n",
        "    },\n",
        "    'efficientdet-d2': {\n",
        "        'model_name': 'efficientdet_d2_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 16\n",
        "    },\n",
        "        'efficientdet-d3': {\n",
        "        'model_name': 'efficientdet_d3_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 16\n",
        "    },\n",
        "    'mobilenet-v2-fpnlite': {\n",
        "        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',\n",
        "        'batch_size': 16\n",
        "    }\n",
        "}\n",
        "\n",
        "#in this tutorial we implement the mobilenet-v2-fpnlite\n",
        "#if you want to scale up to larger efficientdet models you will likely need more compute!\n",
        "chosen_model = 'mobilenet-v2-fpnlite'\n",
        "\n",
        "num_steps = 10000 #The more steps, the longer the training. Increase if your loss function is still decreasing and validation metrics are increasing. \n",
        "num_eval_steps = 1000 #Perform evaluation after so many steps\n",
        "\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
        "batch_size = MODELS_CONFIG[chosen_model]['batch_size'] #if you can fit a large batch in memory, it may speed up your training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN8wo1ngY0t6",
        "outputId": "87c83f05-a304-44a4-caa1-7772d43a0d29"
      },
      "source": [
        "#download pretrained models\n",
        "#in this tutorial we already have the model in /workspace/pre_trained_models folder\n",
        "\n",
        "%cd /content/TensorFlow_Sign_Language_Detection/workspace/pre_trained_models\n",
        "\n",
        "import tarfile\n",
        "\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TensorFlow_Sign_Language_Detection/workspace/pre_trained_models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5ta8O4wY2Ku",
        "outputId": "b8c48815-40a7-459e-e7ed-e2ab6f63928e"
      },
      "source": [
        "#my_model_path = models + '/' + custom_model_name\n",
        "my_model_path = '/content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3'\n",
        "print(my_model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J38MnziaY3d5"
      },
      "source": [
        "#prepare\n",
        "#pipeline_fname = my_model_path + '/' + base_pipeline_file\n",
        "pipeline_fname = '/content/TensorFlow_Sign_Language_Detection/workspace/models/my_ssd_mobnet_v2/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config'\n",
        "#fine_tune_checkpoint = pre_trained_models + '/' + model_name + '/checkpoint/ckpt-0'\n",
        "fine_tune_checkpoint = '/content/TensorFlow_Sign_Language_Detection/workspace/pre_trained_models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0'\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XoNON2KY4rs",
        "outputId": "fdb3fd43-4a16-41b1-8ab3-668b2e99a1cc"
      },
      "source": [
        "print(pipeline_fname)\n",
        "print(fine_tune_checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TensorFlow_Sign_Language_Detection/workspace/models/my_ssd_mobnet_v2/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config\n",
            "/content/TensorFlow_Sign_Language_Detection/workspace/pre_trained_models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSeE-FeRY50I",
        "outputId": "e3b1bdfb-a3f2-41e8-9202-4dd5164bca44"
      },
      "source": [
        "#write custom configuration file by slotting our dataset, model checkpoint, and training parameters into the base pipeline file\n",
        "\n",
        "import re\n",
        "\n",
        "%cd /content/TensorFlow_Sign_Language_Detection/workspace/models/my_ssd_mobnet_v2\n",
        "print('writing custom configuration file')\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    \n",
        "    #fine-tune checkpoint type\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "        \n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TensorFlow_Sign_Language_Detection/workspace/models/my_ssd_mobnet_v2\n",
            "writing custom configuration file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpC1Nl0LY7in",
        "outputId": "1a7a50d1-8449-4ad9-d63c-1d9bb5cbe516"
      },
      "source": [
        "%cat /content/TensorFlow_Sign_Language_Detection/workspace/models/my_ssd_mobnet_v2/pipeline_file.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# SSD with Mobilenet v2 FPN-lite (go/fpn-lite) feature extractor, shared box\n",
            "# predictor and focal loss (a mobile version of Retinanet).\n",
            "# Retinanet: see Lin et al, https://arxiv.org/abs/1708.02002\n",
            "# Trained on COCO, initialized from Imagenet classification checkpoint\n",
            "# Train on TPU-8\n",
            "#\n",
            "# Achieves 22.2 mAP on COCO17 Val\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    inplace_batchnorm_update: true\n",
            "    freeze_batchnorm: false\n",
            "    num_classes: 26\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "        use_matmul_gather: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    encode_background_as_zeros: true\n",
            "    anchor_generator {\n",
            "      multiscale_anchor_generator {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        anchor_scale: 4.0\n",
            "        aspect_ratios: [1.0, 2.0, 0.5]\n",
            "        scales_per_octave: 2\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 320\n",
            "        width: 320\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      weight_shared_convolutional_box_predictor {\n",
            "        depth: 128\n",
            "        class_prediction_bias_init: -4.6\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            random_normal_initializer {\n",
            "              stddev: 0.01\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            scale: true,\n",
            "            decay: 0.997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "        num_layers_before_predictor: 4\n",
            "        share_prediction_tower: true\n",
            "        use_depthwise: true\n",
            "        kernel_size: 3\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2_fpn_keras'\n",
            "      use_depthwise: true\n",
            "      fpn {\n",
            "        min_level: 3\n",
            "        max_level: 7\n",
            "        additional_layer_depth: 128\n",
            "      }\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          random_normal_initializer {\n",
            "            stddev: 0.01\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          scale: true,\n",
            "          decay: 0.997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "      override_base_feature_extractor_hyperparams: true\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid_focal {\n",
            "          alpha: 0.25\n",
            "          gamma: 2.0\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    normalize_loc_loss_by_codesize: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  fine_tune_checkpoint_version: V2\n",
            "  fine_tune_checkpoint: \"/content/TensorFlow_Sign_Language_Detection/workspace/pre_trained_models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n",
            "  fine_tune_checkpoint_type: \"detection\"\n",
            "  batch_size: 16\n",
            "  sync_replicas: true\n",
            "  startup_delay_steps: 0\n",
            "  replicas_to_aggregate: 8\n",
            "  num_steps: 10000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    random_crop_image {\n",
            "      min_object_covered: 0.0\n",
            "      min_aspect_ratio: 0.75\n",
            "      max_aspect_ratio: 3.0\n",
            "      min_area: 0.75\n",
            "      max_area: 1.0\n",
            "      overlap_thresh: 0.0\n",
            "    }\n",
            "  }\n",
            "  optimizer {\n",
            "    momentum_optimizer: {\n",
            "      learning_rate: {\n",
            "        cosine_decay_learning_rate {\n",
            "          learning_rate_base: .08\n",
            "          total_steps: 50000\n",
            "          warmup_learning_rate: .026666\n",
            "          warmup_steps: 1000\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  max_number_of_boxes: 100\n",
            "  unpad_groundtruth_tensors: false\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  label_map_path: \"/content/TensorFlow_Sign_Language_Detection/workspace/annotations/train/Letters_label_map.pbtxt\"\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/TensorFlow_Sign_Language_Detection/workspace/annotations/train/Letters.tfrecord\"\n",
            "  }\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  use_moving_averages: false\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  label_map_path: \"/content/TensorFlow_Sign_Language_Detection/workspace/annotations/train/Letters_label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_epochs: 1\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/TensorFlow_Sign_Language_Detection/workspace/annotations/valid/Letters.tfrecord\"\n",
            "  }\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCPufEWBY95J"
      },
      "source": [
        "pipeline_file = '/content/TensorFlow_Sign_Language_Detection/workspace/models/my_ssd_mobnet_v2/pipeline_file.config'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrxgzfVFZADb",
        "outputId": "98fc2d99-dc9f-40c2-8f29-1a9f1b85fb96"
      },
      "source": [
        "print(pipeline_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TensorFlow_Sign_Language_Detection/workspace/models/my_ssd_mobnet_v2/pipeline_file.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j91-v6oeZBWE",
        "outputId": "cb184806-f43e-4e72-9600-be3a444c4f9b"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={my_model_path} \\\n",
        "    --checkpoint_dir={my_model_path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-21 10:58:14.099525: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0521 10:58:16.478784 139644380030848 model_lib_v2.py:1064] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I0521 10:58:16.479020 139644380030848 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0521 10:58:16.479089 139644380030848 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0521 10:58:16.479153 139644380030848 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0521 10:58:16.479244 139644380030848 model_lib_v2.py:1085] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2021-05-21 10:58:16.483974: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-05-21 10:58:16.497218: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-05-21 10:58:16.497273: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (f5cff7157fe5): /proc/driver/nvidia/version does not exist\n",
            "2021-05-21 10:58:16.497684: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/TensorFlow_Sign_Language_Detection/workspace/annotations/valid/Letters.tfrecord']\n",
            "I0521 10:58:16.532886 139644380030848 dataset_builder.py:163] Reading unweighted datasets: ['/content/TensorFlow_Sign_Language_Detection/workspace/annotations/valid/Letters.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/TensorFlow_Sign_Language_Detection/workspace/annotations/valid/Letters.tfrecord']\n",
            "I0521 10:58:16.533150 139644380030848 dataset_builder.py:80] Reading record datasets for input file: ['/content/TensorFlow_Sign_Language_Detection/workspace/annotations/valid/Letters.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0521 10:58:16.533229 139644380030848 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0521 10:58:16.533286 139644380030848 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W0521 10:58:16.534970 139644380030848 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0521 10:58:16.556991 139644380030848 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0521 10:58:20.916965 139644380030848 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0521 10:58:22.241902 139644380030848 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "I0521 10:58:25.343615 139644380030848 checkpoint_utils.py:140] Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "INFO:tensorflow:Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-1\n",
            "I0521 10:59:30.596262 139644380030848 checkpoint_utils.py:149] Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-1\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "2021-05-21 10:59:31.480897: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-05-21 10:59:31.481539: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199995000 Hz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0521 11:00:04.302970 139644380030848 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0521 11:00:04.313986 139644380030848 model_lib_v2.py:940] Finished eval step 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0521 11:00:04.471714 139644380030848 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0521 11:00:18.385383 139644380030848 model_lib_v2.py:940] Finished eval step 100\n",
            "INFO:tensorflow:Performing evaluation on 144 images.\n",
            "I0521 11:00:53.575218 139644380030848 coco_evaluation.py:293] Performing evaluation on 144 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0521 11:00:53.575918 139644380030848 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0521 11:00:53.585087 139644380030848 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.18s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.14s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "INFO:tensorflow:Eval metrics at step 0\n",
            "I0521 11:00:53.930812 139644380030848 model_lib_v2.py:989] Eval metrics at step 0\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.000000\n",
            "I0521 11:00:53.938164 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP: 0.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.000000\n",
            "I0521 11:00:53.939350 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.000000\n",
            "I0521 11:00:53.940281 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "I0521 11:00:53.941117 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.000000\n",
            "I0521 11:00:53.941835 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (medium): 0.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.000000\n",
            "I0521 11:00:53.942522 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (large): 0.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.000000\n",
            "I0521 11:00:53.943157 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@1: 0.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.000000\n",
            "I0521 11:00:53.943795 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@10: 0.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.000000\n",
            "I0521 11:00:53.944409 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100: 0.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "I0521 11:00:53.945061 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.000000\n",
            "I0521 11:00:53.945694 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.000000\n",
            "I0521 11:00:53.946655 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (large): 0.000000\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.691841\n",
            "I0521 11:00:53.947419 139644380030848 model_lib_v2.py:992] \t+ Loss/localization_loss: 0.691841\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 1.144366\n",
            "I0521 11:00:53.948124 139644380030848 model_lib_v2.py:992] \t+ Loss/classification_loss: 1.144366\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.153446\n",
            "I0521 11:00:53.948732 139644380030848 model_lib_v2.py:992] \t+ Loss/regularization_loss: 0.153446\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 1.989653\n",
            "I0521 11:00:53.949318 139644380030848 model_lib_v2.py:992] \t+ Loss/total_loss: 1.989653\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "I0521 11:04:30.646812 139644380030848 checkpoint_utils.py:140] Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "INFO:tensorflow:Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-2\n",
            "I0521 11:05:17.960592 139644380030848 checkpoint_utils.py:149] Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-2\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0521 11:05:31.038378 139644380030848 model_lib_v2.py:940] Finished eval step 0\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0521 11:05:45.469819 139644380030848 model_lib_v2.py:940] Finished eval step 100\n",
            "INFO:tensorflow:Performing evaluation on 144 images.\n",
            "I0521 11:05:51.339207 139644380030848 coco_evaluation.py:293] Performing evaluation on 144 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0521 11:05:51.339824 139644380030848 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0521 11:05:51.348215 139644380030848 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.81s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.39s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.665\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.406\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.393\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.570\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.611\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.612\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613\n",
            "INFO:tensorflow:Eval metrics at step 1000\n",
            "I0521 11:05:52.589958 139644380030848 model_lib_v2.py:989] Eval metrics at step 1000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.391318\n",
            "I0521 11:05:52.598612 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP: 0.391318\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.664933\n",
            "I0521 11:05:52.599697 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.664933\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.406001\n",
            "I0521 11:05:52.600416 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.406001\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "I0521 11:05:52.601036 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.300990\n",
            "I0521 11:05:52.601665 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (medium): 0.300990\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.393092\n",
            "I0521 11:05:52.602255 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (large): 0.393092\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.570038\n",
            "I0521 11:05:52.602886 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@1: 0.570038\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.610789\n",
            "I0521 11:05:52.603511 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@10: 0.610789\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.612071\n",
            "I0521 11:05:52.604095 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100: 0.612071\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "I0521 11:05:52.604707 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.500000\n",
            "I0521 11:05:52.605296 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.500000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.612872\n",
            "I0521 11:05:52.607062 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (large): 0.612872\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.166703\n",
            "I0521 11:05:52.607691 139644380030848 model_lib_v2.py:992] \t+ Loss/localization_loss: 0.166703\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.487520\n",
            "I0521 11:05:52.608317 139644380030848 model_lib_v2.py:992] \t+ Loss/classification_loss: 0.487520\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.151666\n",
            "I0521 11:05:52.608958 139644380030848 model_lib_v2.py:992] \t+ Loss/regularization_loss: 0.151666\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.805889\n",
            "I0521 11:05:52.609627 139644380030848 model_lib_v2.py:992] \t+ Loss/total_loss: 0.805889\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "I0521 11:10:18.051248 139644380030848 checkpoint_utils.py:140] Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "INFO:tensorflow:Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-3\n",
            "I0521 11:10:45.368895 139644380030848 checkpoint_utils.py:149] Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-3\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0521 11:10:58.630921 139644380030848 model_lib_v2.py:940] Finished eval step 0\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0521 11:11:13.186577 139644380030848 model_lib_v2.py:940] Finished eval step 100\n",
            "INFO:tensorflow:Performing evaluation on 144 images.\n",
            "I0521 11:11:18.848780 139644380030848 coco_evaluation.py:293] Performing evaluation on 144 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0521 11:11:18.849521 139644380030848 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0521 11:11:18.857824 139644380030848 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.43s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.694\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.929\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.892\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.603\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.695\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.751\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.752\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.752\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753\n",
            "INFO:tensorflow:Eval metrics at step 2000\n",
            "I0521 11:11:20.419619 139644380030848 model_lib_v2.py:989] Eval metrics at step 2000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.694401\n",
            "I0521 11:11:20.428590 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP: 0.694401\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.928675\n",
            "I0521 11:11:20.429750 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.928675\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.892083\n",
            "I0521 11:11:20.430627 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.892083\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "I0521 11:11:20.431291 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.602970\n",
            "I0521 11:11:20.431950 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (medium): 0.602970\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.694986\n",
            "I0521 11:11:20.432621 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (large): 0.694986\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.751126\n",
            "I0521 11:11:20.433265 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@1: 0.751126\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.752408\n",
            "I0521 11:11:20.433935 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@10: 0.752408\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.752408\n",
            "I0521 11:11:20.434579 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100: 0.752408\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "I0521 11:11:20.435202 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.600000\n",
            "I0521 11:11:20.435840 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.600000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.753370\n",
            "I0521 11:11:20.436805 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (large): 0.753370\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.078912\n",
            "I0521 11:11:20.437398 139644380030848 model_lib_v2.py:992] \t+ Loss/localization_loss: 0.078912\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.271332\n",
            "I0521 11:11:20.438015 139644380030848 model_lib_v2.py:992] \t+ Loss/classification_loss: 0.271332\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.147578\n",
            "I0521 11:11:20.438615 139644380030848 model_lib_v2.py:992] \t+ Loss/regularization_loss: 0.147578\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.497822\n",
            "I0521 11:11:20.439205 139644380030848 model_lib_v2.py:992] \t+ Loss/total_loss: 0.497822\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "I0521 11:15:45.428302 139644380030848 checkpoint_utils.py:140] Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "INFO:tensorflow:Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-4\n",
            "I0521 11:16:05.645267 139644380030848 checkpoint_utils.py:149] Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-4\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0521 11:16:18.666415 139644380030848 model_lib_v2.py:940] Finished eval step 0\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0521 11:16:33.232184 139644380030848 model_lib_v2.py:940] Finished eval step 100\n",
            "INFO:tensorflow:Performing evaluation on 144 images.\n",
            "I0521 11:16:50.235237 139644380030848 coco_evaluation.py:293] Performing evaluation on 144 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0521 11:16:50.236006 139644380030848 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0521 11:16:50.244001 139644380030848 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.40s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.631\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.858\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.801\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.553\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.631\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.721\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.747\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.550\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.747\n",
            "INFO:tensorflow:Eval metrics at step 3000\n",
            "I0521 11:16:51.747604 139644380030848 model_lib_v2.py:989] Eval metrics at step 3000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.631342\n",
            "I0521 11:16:51.754570 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP: 0.631342\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.858237\n",
            "I0521 11:16:51.755720 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.858237\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.800545\n",
            "I0521 11:16:51.756564 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.800545\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "I0521 11:16:51.757221 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.553465\n",
            "I0521 11:16:51.757931 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (medium): 0.553465\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.631102\n",
            "I0521 11:16:51.758594 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (large): 0.631102\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.721274\n",
            "I0521 11:16:51.759229 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@1: 0.721274\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.733129\n",
            "I0521 11:16:51.759878 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@10: 0.733129\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.746590\n",
            "I0521 11:16:51.760524 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100: 0.746590\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "I0521 11:16:51.761152 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.550000\n",
            "I0521 11:16:51.761790 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.550000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.746911\n",
            "I0521 11:16:51.762757 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (large): 0.746911\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.102278\n",
            "I0521 11:16:51.763338 139644380030848 model_lib_v2.py:992] \t+ Loss/localization_loss: 0.102278\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.331199\n",
            "I0521 11:16:51.763960 139644380030848 model_lib_v2.py:992] \t+ Loss/classification_loss: 0.331199\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.145132\n",
            "I0521 11:16:51.764559 139644380030848 model_lib_v2.py:992] \t+ Loss/regularization_loss: 0.145132\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.578610\n",
            "I0521 11:16:51.765200 139644380030848 model_lib_v2.py:992] \t+ Loss/total_loss: 0.578610\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "I0521 11:21:05.680625 139644380030848 checkpoint_utils.py:140] Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "INFO:tensorflow:Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-5\n",
            "I0521 11:21:25.914320 139644380030848 checkpoint_utils.py:149] Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-5\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0521 11:21:39.245794 139644380030848 model_lib_v2.py:940] Finished eval step 0\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0521 11:21:53.750509 139644380030848 model_lib_v2.py:940] Finished eval step 100\n",
            "INFO:tensorflow:Performing evaluation on 144 images.\n",
            "I0521 11:22:10.564132 139644380030848 coco_evaluation.py:293] Performing evaluation on 144 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0521 11:22:10.564850 139644380030848 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0521 11:22:10.572821 139644380030848 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.42s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.722\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.956\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.927\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.502\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.770\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.771\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.771\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.772\n",
            "INFO:tensorflow:Eval metrics at step 4000\n",
            "I0521 11:22:12.118298 139644380030848 model_lib_v2.py:989] Eval metrics at step 4000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.722341\n",
            "I0521 11:22:12.125179 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP: 0.722341\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.956449\n",
            "I0521 11:22:12.126575 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.956449\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.927367\n",
            "I0521 11:22:12.127567 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.927367\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "I0521 11:22:12.128232 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.501980\n",
            "I0521 11:22:12.128895 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (medium): 0.501980\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.724641\n",
            "I0521 11:22:12.129555 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (large): 0.724641\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.769542\n",
            "I0521 11:22:12.130197 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@1: 0.769542\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.770504\n",
            "I0521 11:22:12.130839 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@10: 0.770504\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.770504\n",
            "I0521 11:22:12.131473 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100: 0.770504\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "I0521 11:22:12.132093 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.500000\n",
            "I0521 11:22:12.132721 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.500000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.771946\n",
            "I0521 11:22:12.133561 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (large): 0.771946\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.067686\n",
            "I0521 11:22:12.134159 139644380030848 model_lib_v2.py:992] \t+ Loss/localization_loss: 0.067686\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.214124\n",
            "I0521 11:22:12.134756 139644380030848 model_lib_v2.py:992] \t+ Loss/classification_loss: 0.214124\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.137501\n",
            "I0521 11:22:12.135342 139644380030848 model_lib_v2.py:992] \t+ Loss/regularization_loss: 0.137501\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.419311\n",
            "I0521 11:22:12.135926 139644380030848 model_lib_v2.py:992] \t+ Loss/total_loss: 0.419311\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "I0521 11:26:26.014745 139644380030848 checkpoint_utils.py:140] Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "INFO:tensorflow:Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-6\n",
            "I0521 11:26:57.279216 139644380030848 checkpoint_utils.py:149] Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-6\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0521 11:27:10.818613 139644380030848 model_lib_v2.py:940] Finished eval step 0\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0521 11:27:25.544863 139644380030848 model_lib_v2.py:940] Finished eval step 100\n",
            "INFO:tensorflow:Performing evaluation on 144 images.\n",
            "I0521 11:27:31.327114 139644380030848 coco_evaluation.py:293] Performing evaluation on 144 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0521 11:27:31.327823 139644380030848 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0521 11:27:31.336223 139644380030848 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.41s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.758\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.953\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.937\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.504\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.760\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.802\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.808\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.808\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.550\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.809\n",
            "INFO:tensorflow:Eval metrics at step 5000\n",
            "I0521 11:27:32.867025 139644380030848 model_lib_v2.py:989] Eval metrics at step 5000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.758272\n",
            "I0521 11:27:32.874445 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP: 0.758272\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.953070\n",
            "I0521 11:27:32.875530 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.953070\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.936912\n",
            "I0521 11:27:32.876266 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.936912\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "I0521 11:27:32.876880 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.503848\n",
            "I0521 11:27:32.878296 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (medium): 0.503848\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.760391\n",
            "I0521 11:27:32.878938 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (large): 0.760391\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.802105\n",
            "I0521 11:27:32.879550 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@1: 0.802105\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.808034\n",
            "I0521 11:27:32.880159 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@10: 0.808034\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.808034\n",
            "I0521 11:27:32.880781 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100: 0.808034\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "I0521 11:27:32.881367 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.550000\n",
            "I0521 11:27:32.881967 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.550000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.809316\n",
            "I0521 11:27:32.882769 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (large): 0.809316\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.058852\n",
            "I0521 11:27:32.883309 139644380030848 model_lib_v2.py:992] \t+ Loss/localization_loss: 0.058852\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.207370\n",
            "I0521 11:27:32.883866 139644380030848 model_lib_v2.py:992] \t+ Loss/classification_loss: 0.207370\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.133288\n",
            "I0521 11:27:32.884416 139644380030848 model_lib_v2.py:992] \t+ Loss/regularization_loss: 0.133288\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.399510\n",
            "I0521 11:27:32.884982 139644380030848 model_lib_v2.py:992] \t+ Loss/total_loss: 0.399510\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "I0521 11:31:57.352601 139644380030848 checkpoint_utils.py:140] Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "INFO:tensorflow:Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-7\n",
            "I0521 11:32:04.516250 139644380030848 checkpoint_utils.py:149] Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-7\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0521 11:32:18.410068 139644380030848 model_lib_v2.py:940] Finished eval step 0\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0521 11:32:33.244297 139644380030848 model_lib_v2.py:940] Finished eval step 100\n",
            "INFO:tensorflow:Performing evaluation on 144 images.\n",
            "I0521 11:32:49.455480 139644380030848 coco_evaluation.py:293] Performing evaluation on 144 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0521 11:32:49.643248 139644380030848 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0521 11:32:49.651569 139644380030848 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.91s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.44s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.712\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.950\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.925\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.456\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.715\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.761\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.762\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.763\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.550\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765\n",
            "INFO:tensorflow:Eval metrics at step 6000\n",
            "I0521 11:32:51.043580 139644380030848 model_lib_v2.py:989] Eval metrics at step 6000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.712268\n",
            "I0521 11:32:51.051834 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP: 0.712268\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.949966\n",
            "I0521 11:32:51.052980 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.949966\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.925259\n",
            "I0521 11:32:51.053835 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.925259\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "I0521 11:32:51.054501 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.455886\n",
            "I0521 11:32:51.055119 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (medium): 0.455886\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.715460\n",
            "I0521 11:32:51.055749 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (large): 0.715460\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.760743\n",
            "I0521 11:32:51.056329 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@1: 0.760743\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.762186\n",
            "I0521 11:32:51.056974 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@10: 0.762186\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.763147\n",
            "I0521 11:32:51.057589 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100: 0.763147\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "I0521 11:32:51.058158 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.550000\n",
            "I0521 11:32:51.058758 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.550000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.764750\n",
            "I0521 11:32:51.059710 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (large): 0.764750\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.067231\n",
            "I0521 11:32:51.060259 139644380030848 model_lib_v2.py:992] \t+ Loss/localization_loss: 0.067231\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.211329\n",
            "I0521 11:32:51.060854 139644380030848 model_lib_v2.py:992] \t+ Loss/classification_loss: 0.211329\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.126795\n",
            "I0521 11:32:51.061411 139644380030848 model_lib_v2.py:992] \t+ Loss/regularization_loss: 0.126795\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.405355\n",
            "I0521 11:32:51.062792 139644380030848 model_lib_v2.py:992] \t+ Loss/total_loss: 0.405355\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "I0521 11:37:04.592631 139644380030848 checkpoint_utils.py:140] Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "INFO:tensorflow:Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-8\n",
            "I0521 11:37:30.833535 139644380030848 checkpoint_utils.py:149] Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-8\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0521 11:37:44.729235 139644380030848 model_lib_v2.py:940] Finished eval step 0\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0521 11:37:59.544110 139644380030848 model_lib_v2.py:940] Finished eval step 100\n",
            "INFO:tensorflow:Performing evaluation on 144 images.\n",
            "I0521 11:38:15.895720 139644380030848 coco_evaluation.py:293] Performing evaluation on 144 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0521 11:38:15.896407 139644380030848 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0521 11:38:15.904931 139644380030848 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.42s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.697\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.958\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.923\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.699\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.739\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.739\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.739\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742\n",
            "INFO:tensorflow:Eval metrics at step 7000\n",
            "I0521 11:38:17.477122 139644380030848 model_lib_v2.py:989] Eval metrics at step 7000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.696735\n",
            "I0521 11:38:17.484509 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP: 0.696735\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.958321\n",
            "I0521 11:38:17.485583 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.958321\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.922953\n",
            "I0521 11:38:17.486303 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.922953\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "I0521 11:38:17.486917 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.402970\n",
            "I0521 11:38:17.487530 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (medium): 0.402970\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.698603\n",
            "I0521 11:38:17.488105 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (large): 0.698603\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.739440\n",
            "I0521 11:38:17.488739 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@1: 0.739440\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.739440\n",
            "I0521 11:38:17.489305 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@10: 0.739440\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.739440\n",
            "I0521 11:38:17.489894 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100: 0.739440\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "I0521 11:38:17.490466 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.400000\n",
            "I0521 11:38:17.491065 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.400000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.741523\n",
            "I0521 11:38:17.491854 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (large): 0.741523\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.071430\n",
            "I0521 11:38:17.492376 139644380030848 model_lib_v2.py:992] \t+ Loss/localization_loss: 0.071430\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.220144\n",
            "I0521 11:38:17.492952 139644380030848 model_lib_v2.py:992] \t+ Loss/classification_loss: 0.220144\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.121585\n",
            "I0521 11:38:17.493500 139644380030848 model_lib_v2.py:992] \t+ Loss/regularization_loss: 0.121585\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.413159\n",
            "I0521 11:38:17.494059 139644380030848 model_lib_v2.py:992] \t+ Loss/total_loss: 0.413159\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "I0521 11:42:30.883867 139644380030848 checkpoint_utils.py:140] Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "INFO:tensorflow:Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-9\n",
            "I0521 11:42:53.113018 139644380030848 checkpoint_utils.py:149] Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-9\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0521 11:43:06.088773 139644380030848 model_lib_v2.py:940] Finished eval step 0\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0521 11:43:20.591348 139644380030848 model_lib_v2.py:940] Finished eval step 100\n",
            "INFO:tensorflow:Performing evaluation on 144 images.\n",
            "I0521 11:43:26.292381 139644380030848 coco_evaluation.py:293] Performing evaluation on 144 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0521 11:43:26.293069 139644380030848 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0521 11:43:26.301442 139644380030848 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.42s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.726\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.940\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.915\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.603\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.728\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.791\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.791\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.791\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792\n",
            "INFO:tensorflow:Eval metrics at step 8000\n",
            "I0521 11:43:27.868962 139644380030848 model_lib_v2.py:989] Eval metrics at step 8000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.726466\n",
            "I0521 11:43:27.876682 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP: 0.726466\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.940265\n",
            "I0521 11:43:27.877824 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.940265\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.914846\n",
            "I0521 11:43:27.878638 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.914846\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "I0521 11:43:27.879280 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.602970\n",
            "I0521 11:43:27.879938 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (medium): 0.602970\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.728214\n",
            "I0521 11:43:27.880584 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (large): 0.728214\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.791003\n",
            "I0521 11:43:27.881228 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@1: 0.791003\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.791484\n",
            "I0521 11:43:27.881862 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@10: 0.791484\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.791484\n",
            "I0521 11:43:27.882500 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100: 0.791484\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "I0521 11:43:27.883120 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.600000\n",
            "I0521 11:43:27.883748 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.600000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.792445\n",
            "I0521 11:43:27.884598 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (large): 0.792445\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.055306\n",
            "I0521 11:43:27.885174 139644380030848 model_lib_v2.py:992] \t+ Loss/localization_loss: 0.055306\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.247344\n",
            "I0521 11:43:27.885771 139644380030848 model_lib_v2.py:992] \t+ Loss/classification_loss: 0.247344\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.115365\n",
            "I0521 11:43:27.886358 139644380030848 model_lib_v2.py:992] \t+ Loss/regularization_loss: 0.115365\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.418016\n",
            "I0521 11:43:27.886959 139644380030848 model_lib_v2.py:992] \t+ Loss/total_loss: 0.418016\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "I0521 11:47:53.213412 139644380030848 checkpoint_utils.py:140] Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "INFO:tensorflow:Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-10\n",
            "I0521 11:48:14.446513 139644380030848 checkpoint_utils.py:149] Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-10\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0521 11:48:27.772792 139644380030848 model_lib_v2.py:940] Finished eval step 0\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0521 11:48:42.492861 139644380030848 model_lib_v2.py:940] Finished eval step 100\n",
            "INFO:tensorflow:Performing evaluation on 144 images.\n",
            "I0521 11:48:59.175831 139644380030848 coco_evaluation.py:293] Performing evaluation on 144 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0521 11:48:59.176551 139644380030848 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0521 11:48:59.184876 139644380030848 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.89s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.41s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.738\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.947\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.930\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.523\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.740\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.789\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.791\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.791\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792\n",
            "INFO:tensorflow:Eval metrics at step 9000\n",
            "I0521 11:49:00.530369 139644380030848 model_lib_v2.py:989] Eval metrics at step 9000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.737697\n",
            "I0521 11:49:00.538513 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP: 0.737697\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.947104\n",
            "I0521 11:49:00.539572 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.947104\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.930084\n",
            "I0521 11:49:00.540291 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.930084\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "I0521 11:49:00.540919 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.522772\n",
            "I0521 11:49:00.541536 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (medium): 0.522772\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.739591\n",
            "I0521 11:49:00.542134 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (large): 0.739591\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.789380\n",
            "I0521 11:49:00.542764 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@1: 0.789380\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.790823\n",
            "I0521 11:49:00.543379 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@10: 0.790823\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.790823\n",
            "I0521 11:49:00.544039 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100: 0.790823\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "I0521 11:49:00.544651 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.600000\n",
            "I0521 11:49:00.545249 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.600000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.791944\n",
            "I0521 11:49:00.546065 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (large): 0.791944\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.057564\n",
            "I0521 11:49:00.546623 139644380030848 model_lib_v2.py:992] \t+ Loss/localization_loss: 0.057564\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.231039\n",
            "I0521 11:49:00.547178 139644380030848 model_lib_v2.py:992] \t+ Loss/classification_loss: 0.231039\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.109535\n",
            "I0521 11:49:00.547739 139644380030848 model_lib_v2.py:992] \t+ Loss/regularization_loss: 0.109535\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.398138\n",
            "I0521 11:49:00.548288 139644380030848 model_lib_v2.py:992] \t+ Loss/total_loss: 0.398138\n",
            "INFO:tensorflow:Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "I0521 11:53:14.544808 139644380030848 checkpoint_utils.py:140] Waiting for new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3\n",
            "INFO:tensorflow:Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-11\n",
            "I0521 11:53:35.766018 139644380030848 checkpoint_utils.py:149] Found new checkpoint at /content/gdrive/MyDrive/Capstone/MY_SSD_MODEL3/ckpt-11\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I0521 11:53:49.424268 139644380030848 model_lib_v2.py:940] Finished eval step 0\n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I0521 11:54:04.028843 139644380030848 model_lib_v2.py:940] Finished eval step 100\n",
            "INFO:tensorflow:Performing evaluation on 144 images.\n",
            "I0521 11:54:20.731018 139644380030848 coco_evaluation.py:293] Performing evaluation on 144 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0521 11:54:20.731861 139644380030848 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0521 11:54:20.740335 139644380030848 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.42s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.774\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.949\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.927\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.603\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.825\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.826\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.826\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.827\n",
            "INFO:tensorflow:Eval metrics at step 10000\n",
            "I0521 11:54:22.299031 139644380030848 model_lib_v2.py:989] Eval metrics at step 10000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.774336\n",
            "I0521 11:54:22.307316 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP: 0.774336\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.948888\n",
            "I0521 11:54:22.308700 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.948888\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.926889\n",
            "I0521 11:54:22.309526 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.926889\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "I0521 11:54:22.310212 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.602970\n",
            "I0521 11:54:22.310891 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (medium): 0.602970\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.775895\n",
            "I0521 11:54:22.311574 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Precision/mAP (large): 0.775895\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.825299\n",
            "I0521 11:54:22.312228 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@1: 0.825299\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.825726\n",
            "I0521 11:54:22.312913 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@10: 0.825726\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.825726\n",
            "I0521 11:54:22.313597 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100: 0.825726\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "I0521 11:54:22.314243 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.600000\n",
            "I0521 11:54:22.314889 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.600000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.827329\n",
            "I0521 11:54:22.315920 139644380030848 model_lib_v2.py:992] \t+ DetectionBoxes_Recall/AR@100 (large): 0.827329\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.049870\n",
            "I0521 11:54:22.316590 139644380030848 model_lib_v2.py:992] \t+ Loss/localization_loss: 0.049870\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.202346\n",
            "I0521 11:54:22.317216 139644380030848 model_lib_v2.py:992] \t+ Loss/classification_loss: 0.202346\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.104081\n",
            "I0521 11:54:22.317849 139644380030848 model_lib_v2.py:992] \t+ Loss/regularization_loss: 0.104081\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 0.356297\n",
            "I0521 11:54:22.318469 139644380030848 model_lib_v2.py:992] \t+ Loss/total_loss: 0.356297\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/model_main_tf2.py\", line 113, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 303, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/models/research/object_detection/model_main_tf2.py\", line 88, in main\n",
            "    wait_interval=300, timeout=FLAGS.eval_timeout)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1111, in eval_continuously\n",
            "    checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 216, in checkpoints_iterator\n",
            "    time.sleep(time_to_next_eval)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngW6mE1oybls"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}